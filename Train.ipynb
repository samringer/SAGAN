{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from DataLoader import CIFAR10DataLoader\n",
    "import hyperparams as hp\n",
    "from SpectralNorm import SpecNorm\n",
    "from Discriminator import Discriminator\n",
    "from Generator import Generator\n",
    "from math import log\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "from random import randint\n",
    "from Attention import AttentionMech\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTO DO:\\nDiscriminator projection\\nuse PyTorch utils specnorm\\nspec norm on everything (inc embeddings)\\nattention\\nrewrite so res connections are v clear\\nminibatch std div?\\nput losses in a seperate func\\nWe use C¯ = C/8 in all our experiments.\\nBigger\\nTransformer attention\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TO DO:\n",
    "Discriminator projection\n",
    "use PyTorch utils specnorm\n",
    "spec norm on everything (inc embeddings)\n",
    "attention\n",
    "rewrite so res connections are v clear\n",
    "minibatch std div?\n",
    "put losses in a seperate func\n",
    "We use C¯ = C/8 in all our experiments.\n",
    "Bigger\n",
    "Transformer attention\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_log_dir='/home/sam/experiments/SAGAN/logs/'\n",
    "exp_dir = 'Overtrain_Attn_DisGen'\n",
    "exp_path = os.path.join(root_log_dir, exp_dir)\n",
    "if not os.path.exists(exp_path):\n",
    "    os.mkdir(exp_path)\n",
    "    \n",
    "writer = SummaryWriter(exp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_im(data):\n",
    "    im = (data * 0.5) + 0.5\n",
    "    im = transforms.ToPILImage()(im)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if hp.use_cuda:\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_g = optim.Adam(generator.parameters(), lr = 0.0001, betas=(0,0.9))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr = 0.0004, betas=(0.0,0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = CIFAR10DataLoader(hp.bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "> /home/sam/git/SAGAN/Generator.py(28)forward()\n",
      "-> x = self.block_1(x, cls)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  p x.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512, 1, 1])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/sam/git/SAGAN/Generator.py(29)forward()\n",
      "-> x = self.block_2(x, cls)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(hp.train_epochs):\n",
    "    print(epoch)\n",
    "    for i, data in enumerate(dl):\n",
    "        \n",
    "        step_no = (epoch*len(dl))+i\n",
    "        \n",
    "        real_ims = data['image']\n",
    "        real_cls = data['labels']\n",
    "        lv = torch.Tensor(hp.bs,hp.latent_space_dim, 1, 1)\n",
    "        lv = lv.normal_()\n",
    "        #gen_cls = torch.tensor(randint(0,hp.num_classes))\n",
    "        gen_cls = torch.tensor(1).repeat(hp.bs)\n",
    "        \n",
    "        if hp.use_cuda:\n",
    "            real_ims = real_ims.cuda()\n",
    "            lv = lv.cuda()\n",
    "            real_cls = real_cls.cuda()\n",
    "            gen_cls = gen_cls.cuda()\n",
    "            \n",
    "        gen_ims = generator(lv, gen_cls)\n",
    "        \n",
    "        # Use hinge loss\n",
    "        d_fake_score = nn.ReLU()(1.0 + discriminator(gen_ims, gen_cls))\n",
    "        d_real_score = nn.ReLU()(1.0 - discriminator(real_ims, real_cls))\n",
    "        loss_d = d_fake_score.mean() + d_real_score.mean()\n",
    "        optimizer_d.zero_grad()\n",
    "        loss_d.backward()\n",
    "        optimizer_d.step()\n",
    "        \n",
    "        gen_ims = generator(lv, gen_cls)\n",
    "        loss_g = - torch.mean(discriminator(gen_ims, gen_cls))\n",
    "        optimizer_g.zero_grad()\n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "        \n",
    "        if step_no % hp.ts_log_interval == 0:\n",
    "            im_to_log = (gen_ims[0] * 0.5) + 0.5\n",
    "            im_file_name = 'generated_images/{}'.format(epoch)\n",
    "            writer.add_image(im_file_name,im_to_log,step_no)\n",
    "            writer.add_scalar('Train/Generator_loss',loss_g,step_no)\n",
    "            writer.add_scalar('Train/Discriminator_loss',loss_d,step_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = CIFAR10DataLoader(hp.bs)\n",
    "dis = Discriminator()\n",
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767],\n",
       "        [-0.0767]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis(batch['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv = torch.rand(hp.bs, hp.latent_space_dim, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0551], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis(gen(lv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = (batch * 0.5) + 0.5\n",
    "im = transforms.ToPILImage()(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F54C80A6128>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = CIFAR10DataLoader(hp.bs)\n",
    "dis = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dl))['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = AttentionMech(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.rand([4,100,16,16])\n",
    "out=attn(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 100, 16, 16])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/sam/git/SAGAN/Attention.py(18)forward()\n",
      "-> value = self.key(x)*self.query(x)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  p x.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 32, 32])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  p self.key(x).shaoe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** AttributeError: 'Tensor' object has no attribute 'shaoe'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  p self.key(x).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 32, 32])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  x self.query(x).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** SyntaxError: invalid syntax\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  p self.query(x).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1024, 1024])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-29dfe7872815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/SAGAN/Attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/SAGAN/Attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f,g,prod=attn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 1024])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3365, -0.3623, -0.3527,  ..., -0.4453, -0.4384, -0.4253],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024, 1024])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
